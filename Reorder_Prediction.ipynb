{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinacipher/food-recommendation-suite/blob/main/Reorder_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4ea00bc",
      "metadata": {
        "id": "c4ea00bc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import kagglehub\n",
        "import os\n",
        "import zipfile\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64a69248",
      "metadata": {
        "id": "64a69248"
      },
      "outputs": [],
      "source": [
        "print(\"Downloading dataset...\")\n",
        "path = kagglehub.dataset_download(\"psparks/instacart-market-basket-analysis\")\n",
        "print(\"Dataset downloaded to:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "637b8af4",
      "metadata": {
        "id": "637b8af4"
      },
      "outputs": [],
      "source": [
        "files = os.listdir(path)\n",
        "csv_files = [f for f in files if f.endswith('.csv')]\n",
        "zip_files = [f for f in files if f.endswith('.zip')]\n",
        "\n",
        "data_dir = os.path.join(path, 'extracted')\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "\n",
        "for z in zip_files:\n",
        "    with zipfile.ZipFile(os.path.join(path, z), 'r') as zip_ref:\n",
        "        zip_ref.extractall(data_dir)\n",
        "\n",
        "if len(csv_files) > 0:\n",
        "    for f in csv_files:\n",
        "        df_path = os.path.join(path, f)\n",
        "        os.rename(df_path, os.path.join(data_dir, f))\n",
        "\n",
        "print(\"CSV files available:\", os.listdir(data_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d4ea1df",
      "metadata": {
        "id": "0d4ea1df"
      },
      "outputs": [],
      "source": [
        "orders = pd.read_csv(os.path.join(data_dir, 'orders.csv'))\n",
        "products = pd.read_csv(os.path.join(data_dir, 'products.csv'))\n",
        "order_products_prior = pd.read_csv(os.path.join(data_dir, 'order_products__prior.csv'))\n",
        "order_products_train = pd.read_csv(os.path.join(data_dir, 'order_products__train.csv'))\n",
        "print(\"Data loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f01942a",
      "metadata": {
        "id": "0f01942a"
      },
      "outputs": [],
      "source": [
        "orders['days_since_prior_order'] = orders['days_since_prior_order'].fillna(0)\n",
        "\n",
        "def create_user_product_features(orders_df, order_products_df):\n",
        "    user_product_stats = order_products_df.merge(orders_df[orders_df.eval_set == 'prior'], on='order_id')\n",
        "    user_product_features = user_product_stats.groupby(['user_id', 'product_id']).agg(\n",
        "        up_orders=('order_id', 'count'),\n",
        "        up_first_order=('order_number', 'min'),\n",
        "        up_last_order=('order_number', 'max'),\n",
        "        up_avg_cart_position=('add_to_cart_order', 'mean')\n",
        "    ).reset_index()\n",
        "    return user_product_features\n",
        "\n",
        "def create_user_features(orders_df, order_products_df):\n",
        "    user_stats = orders_df[orders_df.eval_set == 'prior'].groupby('user_id').agg(\n",
        "        user_orders=('order_number', 'max'),\n",
        "        user_period=('days_since_prior_order', 'sum'),\n",
        "        user_avg_days_since_prior=('days_since_prior_order', 'mean')\n",
        "    ).reset_index()\n",
        "    user_order_products = order_products_df.merge(orders_df[orders_df.eval_set == 'prior'], on='order_id')\n",
        "    user_product_stats = user_order_products.groupby('user_id').agg(\n",
        "        user_total_products=('product_id', 'count'),\n",
        "        user_reorder_ratio=('reordered', 'mean')\n",
        "    ).reset_index()\n",
        "    user_features = user_stats.merge(user_product_stats, on='user_id')\n",
        "    return user_features\n",
        "\n",
        "def create_product_features(order_products_df):\n",
        "    product_features = order_products_df.groupby('product_id').agg(\n",
        "        prod_orders=('order_id', 'count'),\n",
        "        prod_reorders=('reordered', 'sum'),\n",
        "        prod_first_orders=('order_id', lambda x: (x == 1).sum()),\n",
        "        prod_second_orders=('order_id', lambda x: (x == 2).sum()),\n",
        "        prod_avg_cart_position=('add_to_cart_order', 'mean')\n",
        "    ).reset_index()\n",
        "    product_features['prod_reorder_probability'] = np.where(\n",
        "        product_features.prod_orders > 0,\n",
        "        product_features.prod_reorders / product_features.prod_orders,\n",
        "        0\n",
        "    )\n",
        "    product_features['prod_reorder_ratio'] = np.where(\n",
        "        product_features.prod_first_orders > 0,\n",
        "        product_features.prod_reorders / product_features.prod_first_orders,\n",
        "        0\n",
        "    )\n",
        "    return product_features.fillna(0)\n",
        "\n",
        "user_product_features = create_user_product_features(orders, order_products_prior)\n",
        "user_features = create_user_features(orders, order_products_prior)\n",
        "product_features = create_product_features(order_products_prior)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f18e87c",
      "metadata": {
        "id": "4f18e87c"
      },
      "outputs": [],
      "source": [
        "train_orders = orders[orders.eval_set == 'train']\n",
        "train = train_orders.merge(user_features, on='user_id')\n",
        "train_products = order_products_train.merge(train_orders, on='order_id')[['user_id', 'product_id', 'reordered']]\n",
        "sample_users = train.user_id.unique()[:5000]\n",
        "train_sample = train[train.user_id.isin(sample_users)]\n",
        "user_products = user_product_features[user_product_features.user_id.isin(sample_users)]\n",
        "train_data = user_products.merge(\n",
        "    train_products[['user_id', 'product_id', 'reordered']],\n",
        "    on=['user_id', 'product_id'],\n",
        "    how='left'\n",
        ")\n",
        "train_data['reordered'] = train_data['reordered'].fillna(0)\n",
        "train_data = train_data.merge(user_features, on='user_id')\n",
        "train_data = train_data.merge(product_features, on='product_id')\n",
        "X = train_data.drop(['user_id', 'product_id', 'reordered'], axis=1)\n",
        "y = train_data['reordered']\n",
        "feature_names = X.columns.tolist()\n",
        "X = X.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bbfce76",
      "metadata": {
        "id": "8bbfce76"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "model = RandomForestClassifier(n_estimators=30, random_state=42, n_jobs=-1, max_depth=10, class_weight='balanced')\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7e72def",
      "metadata": {
        "id": "d7e72def"
      },
      "outputs": [],
      "source": [
        "feature_importance = pd.DataFrame({'feature': feature_names,'importance': model.feature_importances_}).sort_values('importance', ascending=False)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='importance', y='feature', data=feature_importance.head(10))\n",
        "plt.title('Top 10 Feature Importance')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf42bf4e",
      "metadata": {
        "id": "bf42bf4e"
      },
      "outputs": [],
      "source": [
        "def predict_reorders(user_id, model, scaler, user_features, product_features, user_product_features, feature_names, top_n=10):\n",
        "    user_data = user_features[user_features.user_id == user_id]\n",
        "    user_products = user_product_features[user_product_features.user_id == user_id]\n",
        "    if len(user_products) == 0:\n",
        "        return []\n",
        "    user_products = user_products.merge(product_features, on='product_id')\n",
        "    for col in user_data.columns:\n",
        "        if col != 'user_id':\n",
        "            user_products[col] = user_data[col].values[0]\n",
        "    X_user = user_products[feature_names].copy()\n",
        "    X_user = X_user.fillna(0)\n",
        "    X_user_scaled = scaler.transform(X_user)\n",
        "    probabilities = model.predict_proba(X_user_scaled)[:, 1]\n",
        "    user_products['reorder_probability'] = probabilities\n",
        "    top_products = user_products.sort_values('reorder_probability', ascending=False).head(top_n)\n",
        "    return top_products[['product_id', 'reorder_probability']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8e299ec",
      "metadata": {
        "id": "e8e299ec"
      },
      "outputs": [],
      "source": [
        "user_id_example = 1\n",
        "top_reorders = predict_reorders(user_id_example, model, scaler, user_features, product_features,\n",
        "                               user_product_features, feature_names)\n",
        "print(top_reorders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "615ae7da",
      "metadata": {
        "id": "615ae7da"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(model, 'reorder_prediction_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "joblib.dump(feature_names, 'feature_names.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bdbbb89",
      "metadata": {
        "id": "2bdbbb89"
      },
      "outputs": [],
      "source": [
        "def load_and_predict(user_id, user_features, product_features, user_product_features):\n",
        "    model = joblib.load('reorder_prediction_model.pkl')\n",
        "    scaler = joblib.load('scaler.pkl')\n",
        "    feature_names = joblib.load('feature_names.pkl')\n",
        "    return predict_reorders(user_id, model, scaler, user_features, product_features,\n",
        "                           user_product_features, feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a267afb",
      "metadata": {
        "id": "7a267afb"
      },
      "outputs": [],
      "source": [
        "user_id_example = 2\n",
        "top_reorders = load_and_predict(user_id_example, user_features, product_features, user_product_features)\n",
        "print(top_reorders)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}