{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e627d99",
   "metadata": {},
   "source": [
    "# Project 3 - Supervised Top-N Ranking\n",
    "\n",
    "This notebook is self-contained and uses synthetic data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6948205",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, r2_score\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)\n",
    "print('Imports ready')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95aa482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Synthetic interactions for ranking\n",
    "n_users=500; n_items=180\n",
    "users=pd.DataFrame({'user_id':np.arange(1,n_users+1),'segment':np.random.choice(['A','B','C'],n_users)})\n",
    "items=pd.DataFrame({'item_id':np.arange(1,n_items+1),'cuisine':np.random.choice(['Pizza','Burger','Sushi','Indian','Mexican','Salad','Dessert'],n_items),'price':np.round(np.random.normal(12,4,n_items).clip(3,60),2)})\n",
    "rows=[]\n",
    "for u in users['user_id']:\n",
    "    pref = np.random.choice(items['cuisine'].unique())\n",
    "    sampled = items.sample(40)\n",
    "    for _,it in sampled.iterrows():\n",
    "        relevance = 3 + (it['cuisine']==pref)*1.5 - 0.01*it['price'] + np.random.normal(0,0.6)\n",
    "        rows.append({'user_id':u,'item_id':it['item_id'],'relevance':np.clip(relevance,1,5)})\n",
    "inter = pd.DataFrame(rows)\n",
    "inter.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac36a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Features and model training (regressor for relevance)\n",
    "df = inter.merge(users,on='user_id').merge(items,on='item_id')\n",
    "df = pd.get_dummies(df, columns=['cuisine','segment'], drop_first=True)\n",
    "features = [c for c in df.columns if c not in ['user_id','item_id','relevance']]\n",
    "X=df[features]; y=df['relevance']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "gbr=GradientBoostingRegressor(n_estimators=200, random_state=42).fit(X_train,y_train)\n",
    "print('Rank model RMSE:', mean_squared_error(y_test,gbr.predict(X_test),squared=False))\n",
    "# recommend function\n",
    "def recommend_topN(user_id, top_n=10):\n",
    "    user = users[users['user_id']==user_id] if user_id in users['user_id'].values else users.sample(1)\n",
    "    cand = items.copy()\n",
    "    cand['user_id']=user['user_id'].iloc[0]\n",
    "    merged = cand.merge(user, on='user_id', how='left')\n",
    "    merged = pd.get_dummies(merged, columns=['cuisine','segment'], drop_first=True)\n",
    "    for col in X.columns:\n",
    "        if col not in merged.columns:\n",
    "            merged[col]=0\n",
    "    scores = gbr.predict(merged[X.columns])\n",
    "    merged['score']=scores\n",
    "    return merged.sort_values('score',ascending=False).head(top_n)[['item_id','cuisine','price','score']]\n",
    "print(recommend_topN(users['user_id'].sample(1).iloc[0], top_n=8))\n",
    "with open('project3_rank_gbr.pkl','wb') as f:\n",
    "    pickle.dump(gbr,f)\n",
    "print('Saved project3_rank_gbr.pkl')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
